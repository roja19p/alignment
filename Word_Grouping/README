*****************************************How to run the English-Hindi grouping module on a single sentence from scratch.**********************************************

###Contact info 
Parse_Generator.sh created by Yukti Handuja and Raj Rajeshwari Kayan [yukti1106@gmail.com, rajrajeshwarikayan@gmail.com]
Run_Grouping_Files.sh created by Saumya Navneet [saumyanavneet26@gmail.com]
Last updated November 27, 2019

#PREREQUISITE#################
You should have:
	Anaconda (Google search)
	Python2.7 (comes by default in Ubuntu, check: python -V; if not there install)
	Anusaaraka (Anusaaraka ReadMe)
	stanford-parser-full-2018-10-17(Step 1)  
	Irshad Parser(Step 2)
	Word_Grouping Folder(GitHub)
	GCIDE
	WordNet(Princeton University)
	
Additionally:
	Create a test_tmp folder in tmp_anu_dir/tmp(instructions given in step 3)

************************************************************************************************************************************************************

#STEP 1:: Installation of Anusaaraka : Install Anusaaraka from Readme provided ###########################################
	1. This module requires us to use the 2018 version of the Stanford parser.
	2. Check the folder $HOME/anusaaraka/Parsers/stanford-parser for stanford-parser-full-2018-10-17.
	3. If the folder is not available, then download the folder from the following link and extract it in $HOME/anusaaraka/Parsers/stanford-parser folder
	https://nlp.stanford.edu/software/lex-parser.shtml
	
#STEP 2:: Installation of Irshad's Hindi Parser #########################################################################

1. Setup the path in bash for csnlp, for that copy following line at the enf of ~/.bashrc
	export hindi_parser=<path...to ...csnlp folder>  [to be on the safer side, make the csnlp folder and do these steps in the Home directory itself]
	source ~/.bashrc
2. create python2.7 conda environment
	conda create -n python2.7 python=2.7
3. activate python2.7 environment
	source activate python2.7
4. clone the parser directory 
	git clone https://github.com/PawarKishori/csnlp.git
5. go inside the directory.
	cd csnlp
6. Install the parser requirements, either using conda or pip, but in the same python directory in which environment is activated.
	6.1.1 Install gensim package 
		conda install -c anaconda gensim 
	6.2.1 Install pip (as dynet will be installed using pip)
		sudo apt-get install python-pip  
	6.2.2 Install dynet using pip, as it was not available in conda
		/home/...path to python/anaconda2/bin/python2.7 -m pip install dynet
	6.2.3 Download the models for parser	
		git clone https://bitbucket.org/irshadbhat/nsdp-cs-models/src/c775772ec71639907771603c3071afe79e1382d9/PANINI/HI/PARSER
	6.2.4 Unzip using bunzip command:
		1) cd $hindi_parser/PARSER/PANINI/HI/PARSER
		2) bunzip2 *.bz2
		3) cd $hindi_parser/PARSER/UD/HI/PARSER
		4) bunzip2 *.bz2

7. Integrating tokenizer 
	7.1 cd $hindi_parser 
	7.2 clone tokenizer
		git clone https://irshadbhat@bitbucket.org/iscnlp/tokenizer.git
	7.3 cd tokenizer
	7.4 sudo python setup.py install ( prerequisite for 7.4 : sudo apt-get install python-setuptools)


8. Testing : Hindi parser run command

	Run parser with tokenizer:
	sh run_hindi_parser.sh /absolute/path/to/input_wx/file output_file	
	sh run_hindi_parser.sh $HOME/csnlp/demo demo.out

#STEP 3::Preparation#############################################################
**********Necessary steps to perform the first time you run the module***********

	1. In tmp_anu_dir go inside the tmp folder. Create a folder named test_tmp.
	2. Inside the test_tmp folder create a folder named 2.1
	3. Inside this folder(2.1) create two files E_sentence and H_sentence (case sensitive). These files contain the English and the Hindi(wx format) sentences respectively.
	4. In your home directory paste this folder(Word_Grouping)
	
#STEP 4:: Run the modules########################################################### 

	Go to Word_Grouping folder 
	open the terminal from the folder and run:
		sh Parse_Generator.sh $1 $2
			instead of $1 and $2 enter the following parameters:
			$1 -> $HOME/tmp_anu_dir/tmp/test_tmp/2.1/E_sentence
			$2 -> $HOME/tmp_anu_dir/tmp/test_tmp/2.1
	after the above command is executed successfully, run the following command:
		sh Run_Grouping_Files.sh test
		
**************************************************************************************************

ADDITIONAL NOTES:
	1. E_sentence and H_sentence file in 2.1 folder created inside test_tmp(made in step 3) needs to be changed for every new sentence that you want to run.
		E_sentence will have the English sentence
		H_sentence will have its Hindi equivalent sentence in WX format

	2. Steps 1 to 3 need to be done only once. Just change the sentence files and run step 4.

